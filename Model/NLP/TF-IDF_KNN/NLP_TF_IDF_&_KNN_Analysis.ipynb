{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7ffpZmA3mJC",
        "outputId": "44ff46e4-dc48-4ace-a03d-6eaf44f9a39d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/209.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sastrawi\n",
            "Successfully installed sastrawi-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
      ],
      "metadata": {
        "id": "KPGFImQw2_0a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Muat dataset JSON\n",
        "url = \"https://raw.githubusercontent.com/Nocturnailed-Community/Pamolah-Intelegent/refs/heads/main/Datasets/NLP/augmented_realistic_dataset.json\"\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    dataset = response.json()\n",
        "    print(\"Dataset berhasil diambil dari URL!\")\n",
        "else:\n",
        "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
        "    dataset = None\n",
        "\n",
        "if dataset:\n",
        "    with open(\"augmented_realistic_dataset.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(dataset, f, ensure_ascii=False, indent=4)\n",
        "    print(\"Dataset berhasil disimpan ke file lokal.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQOFI-ic4Ghp",
        "outputId": "99c58a8b-3adb-4033-cf2b-1e365c42756d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset berhasil diambil dari URL!\n",
            "Dataset berhasil disimpan ke file lokal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Ambil data dan label\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "for entry in dataset:\n",
        "    # Gabungkan semua fitur teks menjadi satu input\n",
        "    text = f\"{entry['keluhan_umum']} {entry['lokasi_nyeri']} {entry['durasi_masalah']} {entry['gejala_tambahan']}\"\n",
        "    texts.append(text)\n",
        "    labels.append(entry['kelas'])\n",
        "\n",
        "# Step 3: Encoding label menjadi format numerik\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Step 4: Preprocess dengan menghilangkan stop words menggunakan Sastrawi dan Stemming\n",
        "stopword_factory = StopWordRemoverFactory()\n",
        "stopword_remover = stopword_factory.create_stop_word_remover()\n",
        "\n",
        "stemmer_factory = StemmerFactory()\n",
        "stemmer = stemmer_factory.create_stemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Menghapus stop words\n",
        "    text_no_stopwords = stopword_remover.remove(text)\n",
        "    # Stemming\n",
        "    text_stemmed = stemmer.stem(text_no_stopwords)\n",
        "    return text_stemmed\n",
        "\n",
        "# Menggunakan preprocessing (stop words removal dan stemming)\n",
        "preprocessed_texts = [preprocess_text(text) for text in texts]"
      ],
      "metadata": {
        "id": "QOM5I7V275ma"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: TF-IDF Vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=15000,  # Gunakan maksimal 15.000 fitur\n",
        "    ngram_range=(1, 2),  # Gunakan unigram dan bigram\n",
        "    stop_words='english'  # Tambahkan stopwords tambahan (optional)\n",
        ")\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(preprocessed_texts)\n",
        "\n",
        "# Step 6: Split dataset menjadi train dan test\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 7: Grid Search untuk mencari nilai k terbaik dan metrik jarak terbaik\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],  # Mencoba berbagai nilai k\n",
        "    'metric': ['cosine', 'euclidean', 'manhattan']  # Mencoba beberapa metrik\n",
        "}\n",
        "knn = KNeighborsClassifier()\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')  # 5-fold cross-validation\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 8: Menampilkan parameter terbaik dari Grid Search\n",
        "print(\"Best Parameters from Grid Search:\", grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpsNO66K7_Lc",
        "outputId": "f31e7d15-17bd-4bd7-d0b5-2dce01d454d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters from Grid Search: {'metric': 'cosine', 'n_neighbors': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Menggunakan model terbaik dari Grid Search\n",
        "best_knn_model = grid_search.best_estimator_\n",
        "\n",
        "# Step 10: Evaluasi model\n",
        "y_pred = best_knn_model.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts1bSu3k8EUU",
        "outputId": "71be34c0-5045-4640-ac17-1ec177d801aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Abscess       1.00      0.99      0.99       617\n",
            "      Caries       0.98      1.00      0.99      1400\n",
            "  Gingivitis       0.99      1.00      0.99      1166\n",
            "      Normal       0.99      0.86      0.92       420\n",
            "      Plaque       0.95      0.98      0.96       797\n",
            "\n",
            "    accuracy                           0.98      4400\n",
            "   macro avg       0.98      0.97      0.97      4400\n",
            "weighted avg       0.98      0.98      0.98      4400\n",
            "\n",
            "Accuracy: 98.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Simpan model KNN\n",
        "joblib.dump(best_knn_model, 'knn_model.pkl')\n",
        "\n",
        "# Simpan tfidf vectorizer\n",
        "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n",
        "\n",
        "# Simpan label encoder\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnpvT54l6cvm",
        "outputId": "7146796e-897f-4d50-bb2a-306213762324"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat kembali model, tfidf vectorizer, dan label encoder\n",
        "knn_model = joblib.load('knn_model.pkl')\n",
        "tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
        "label_encoder = joblib.load('label_encoder.pkl')\n",
        "\n",
        "# Verifikasi jika berhasil memuat model\n",
        "print(\"Model, TF-IDF Vectorizer, dan Label Encoder berhasil dimuat!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DYU9aHd6pkP",
        "outputId": "049b2c08-b0ef-486c-8f48-e9551b5cf71b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model, TF-IDF Vectorizer, dan Label Encoder berhasil dimuat!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "# Preprocessing text\n",
        "stopword_factory = StopWordRemoverFactory()\n",
        "stopword_remover = stopword_factory.create_stop_word_remover()\n",
        "\n",
        "stemmer_factory = StemmerFactory()\n",
        "stemmer = stemmer_factory.create_stemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text_no_stopwords = stopword_remover.remove(text)\n",
        "    text_stemmed = stemmer.stem(text_no_stopwords)\n",
        "    return text_stemmed\n",
        "\n",
        "# Input text untuk diuji\n",
        "text = \"saya merasa nyeri di bagian belakang gigi\"\n",
        "\n",
        "# Preprocess input text\n",
        "preprocessed_text = preprocess_text(text)\n",
        "\n",
        "# Transformasi teks menjadi fitur tf-idf\n",
        "input_tfidf = tfidf_vectorizer.transform([preprocessed_text])\n",
        "\n",
        "# Prediksi label\n",
        "predicted_label = knn_model.predict(input_tfidf)\n",
        "predicted_class = label_encoder.inverse_transform(predicted_label)\n",
        "\n",
        "# Output hasil prediksi\n",
        "print(f\"Hasil prediksi untuk teks: '{text}' adalah kelas '{predicted_class[0]}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQm68NBG6t0P",
        "outputId": "500b9145-89bb-42f0-bb1a-5bdb6d1c00fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil prediksi untuk teks: 'saya merasa nyeri di bagian belakang gigi' adalah kelas 'Gingivitis'\n"
          ]
        }
      ]
    }
  ]
}